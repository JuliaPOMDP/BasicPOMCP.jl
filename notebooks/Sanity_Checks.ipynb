{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addprocs(30);\n",
    "using Distributed\n",
    "addprocs(7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPModels\n",
    "using BasicPOMCP\n",
    "using POMDPs\n",
    "using POMDPPolicies\n",
    "\n",
    "@everywhere begin\n",
    "    using POMDPModels\n",
    "    using BasicPOMCP\n",
    "    using POMDPs\n",
    "    using BeliefUpdaters\n",
    "    using Random\n",
    "    using POMDPSimulators\n",
    "    using POMDPModelTools\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000;\n",
    "# N = 100;\n",
    "problem = BabyPOMDP(-5, -10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "est_reward (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function est_reward(problem, policy, belief, N; eps=0.01)\n",
    "    sum = @distributed (+) for i in 1:N\n",
    "        sim_rng = MersenneTwister(i)\n",
    "        sim = RolloutSimulator(rng=sim_rng, eps=eps)\n",
    "        if isa(policy, FeedWhenCrying)\n",
    "            up = updater(policy)\n",
    "        else\n",
    "            up = DiscreteUpdater(problem)\n",
    "        end\n",
    "        POMDPs.simulate(sim, problem, policy, up, initialize_belief(up,belief), false)\n",
    "    end\n",
    "    return sum/N;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.528358 seconds (3.23 M allocations: 163.269 MiB, 1.60% gc time)\n",
      "-15.978715013004313\n"
     ]
    }
   ],
   "source": [
    "@time er = est_reward(problem, FeedWhenCrying(), false, N)\n",
    "println(er)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than in the crying babies test because epsilon is large and, more importantly, it gets a notcrying observation on the first step every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.274271 seconds (1.57 M allocations: 78.204 MiB, 1.72% gc time)\n",
      "-32.396648905123115\n"
     ]
    }
   ],
   "source": [
    "# Random\n",
    "pol_rng = MersenneTwister(7)\n",
    "@time er = est_reward(problem, RandomPolicy(problem, rng=pol_rng), BoolDistribution(0.5), N)\n",
    "println(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.938545 seconds (1.19 M allocations: 58.761 MiB, 0.45% gc time)\n",
      "-15.746646379594688\n"
     ]
    }
   ],
   "source": [
    "# POMCP with FWC rollout policy\n",
    "rng = MersenneTwister(3)\n",
    "\n",
    "solver = POMCPSolver(estimate_value=RolloutEstimator(FeedWhenCrying()),\n",
    "                    max_depth=44, # eps = 0.01\n",
    "                    c=20.0,\n",
    "                    tree_queries=300, \n",
    "                    rng=rng)\n",
    "                    \n",
    "\n",
    "policy = solve(solver, problem)\n",
    "\n",
    "@time er = est_reward(problem, policy, BoolDistribution(0.0), N)\n",
    "println(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.203904 seconds (315.30 k allocations: 16.039 MiB, 0.86% gc time)\n",
      "-16.023154545048516\n"
     ]
    }
   ],
   "source": [
    "# POMCP with Random rollout policy\n",
    "rng = MersenneTwister(2)\n",
    "rollout_pol_rng = MersenneTwister(2)\n",
    "\n",
    "solver = POMCPSolver(estimate_value=RolloutEstimator(RandomPolicy(problem, rng=rollout_pol_rng)),\n",
    "                     max_depth=44, # eps = 0.01\n",
    "                     c=20.0,\n",
    "                     tree_queries=300, \n",
    "                     rng=rng)\n",
    "\n",
    "policy = solve(solver, problem)\n",
    "\n",
    "@time er = est_reward(problem, policy, BoolDistribution(0.0), N)\n",
    "println(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.168666 seconds (162.41 k allocations: 8.239 MiB)\n",
      "-15.525869513040346\n"
     ]
    }
   ],
   "source": [
    "# Optimal policy for these particular problem parameters:\n",
    "# if the belief that the baby is hungry is over .28206, then feed (see DMU book)\n",
    "@everywhere begin\n",
    "    struct OptBabyPolicy <: POMDPs.Policy end\n",
    "    function POMDPs.action(p::OptBabyPolicy, b)\n",
    "        a = pdf(b, true)>0.28206\n",
    "        return a\n",
    "    end\n",
    "    POMDPs.updater(::OptBabyPolicy) = updater(BabyPOMDP(-5,-10))\n",
    "end\n",
    "@time er = est_reward(problem, OptBabyPolicy(), BoolDistribution(0.0), N)\n",
    "println(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
